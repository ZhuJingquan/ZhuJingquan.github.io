---
layout:     post
title:      "Hello 2015"
subtitle:   " \"Hello World, Hello Blog\""
date:       2015-01-29 12:00:00
author:     "Hux"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - 生活
---

> “Yeah It's on. ”

推荐神器 ：aptitude



Ps: 终于折腾出来一个写字的好地方，乔迁之喜,😄

### 机器学习入门

#### 第一章 主要是基本概念，以及一个（No launch Free Theory）的推导

概念参考知乎上的这个[系列](https://zhuanlan.zhihu.com/p/27900874)

NLF理论

#### 第二章 主要是模型评估与选择

1 基本概念

- 分类 对离散结果的预测；

- 回归 对连续结果的预测；

- 训练误差、经验误差[https://www.quora.com/What-is-a-training-and-test-error](http://link.zhihu.com/?target=https%3A//www.quora.com/What-is-a-training-and-test-error)

- 泛华误差

  **任何学习算法都有针对过拟合的措施，但过拟合是无法完全避免的**

  > 努力使经验误差最小化，是指在“过拟合”与“欠拟合”之间寻找一种平衡，并尽可能的使学习器在不太过拟合的情况下使得训练集的分类更准确。

2 模型好坏的评估

> **理想**：通过评估学习器的**泛化误差**，选出泛化误差最小的学习器。
>
> **实际**：泛化误差只能通过测试求得的**测试误差**来表现

如何获取测试集

- **留出法** 
  $$
  D=S\cup T,S\cap T=\phi
  $$
  ​

- **交叉验证法**
  $$
  D=D_1 \cup D_2 \cup \dots \cup D_k; \\ D_i \cup D_j = \phi
  $$
  ​

> 交叉验证法得到的结果是均值的均值，即p个“k个结果的均值”的均值，因此交叉验证法又可以叫做**p次k折交叉验证**。
>
> 交叉验证法的特点：1.每个子集都会做测试集、2、每个子集分层采样、3.单次k折，切换测试集试验取均值、4.k折划分p次，重复试验再取均值
>
> 优点：准确；缺点：开销大
>
> p.s.上面两幅图，用**点到圆心的距离**来体现数据分布的一致性，任何子集均有与圆心距离在0到半径长度范围内的点。

- **自助法**

  每次有放回的进行随你采样m次形成包含m个样例的样本

某样本始终不会被采到的概率
$$
lim_{m\to \infty}(1- \frac {1}{m})^m \to \frac {1}{e} \approx 0.368
$$
3 **模型的性能度量**：泛化误差的评价



![img](https://pic2.zhimg.com/50/v2-0857b2161efa8306a2d263ace3b1a996_hd.jpg)

[继续总结](https://zhuanlan.zhihu.com/p/28482121)